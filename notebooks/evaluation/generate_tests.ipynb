{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.env_loader import load_api_key\n",
    "together_key = load_api_key(\"TOGETHER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import Together\n",
    "from langchain_together.embeddings import TogetherEmbeddings\n",
    "\n",
    "# together_key = \"<your-key-here>\"\n",
    "\n",
    "embeddings = TogetherEmbeddings(model=\"togethercomputer/m2-bert-80M-8k-retrieval\")\n",
    "\n",
    "together_completion = Together(\n",
    "    model=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=4000,\n",
    "    top_k=1,\n",
    "    together_api_key=together_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hilla/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/.venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `Together` was deprecated in LangChain 0.0.12 and will be removed in 0.3. An updated version of the class exists in the langchain-together package and should be used instead. To use it run `pip install -U langchain-together` and import as `from langchain_together import Together`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Together AI recently raised $102.5M in funding, created the RedPajama Datasets with 30 trillion tokens, and released the StripedHyena models, which are competitive in short and long-context evaluations.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_together import TogetherEmbeddings\n",
    "from langchain_community.llms import Together\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"Together AI provides the fastest cloud platform for building and running generative AI.\",\n",
    "     \"Together AI recently released their StripedHyena models, which is the first alternative model competitive with the best open-source Transformers in short and long-context evaluations.\",\n",
    "     \"Together AI is also the creator of the RedPajama Datasets. RedPajama-Data-v2 is an open dataset with 30 trillion tokens from 84 CommonCrawl dumps.\",\n",
    "     \"Together AI recently raised $102.5M in a Series A financing to build the future of AI.\"],\n",
    "     TogetherEmbeddings(model=\"togethercomputer/m2-bert-80M-8k-retrieval\")\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "model = Together(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=128,\n",
    "    top_k=50,\n",
    "    # together_api_key=\"...\"\n",
    ")\n",
    "\n",
    "# Provide a template following the LLM's original chat template.\n",
    "template = \"\"\"<s>[INST] Answer the question in a simple sentence based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question} [/INST] \n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template) \n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "input_query = \"What are some recent highlights of Together AI?\"\n",
    "output = chain.invoke(input_query)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import download_loader\n",
    "\n",
    "SemanticScholarReader = download_loader(\"SemanticScholarReader\")\n",
    "loader = SemanticScholarReader()\n",
    "query_space = \"large language models\"\n",
    "documents = loader.load_data(query=query_space, limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the documents locally from .MD files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 1213 chunks.\n",
      "We may put this in another way. Each man is at every moment subjected to several different sets of law but there is only one of these which he is free to disobey. As a body, he is subjected to gravitation and cannot disobey it; if you leave him unsupported in mid-air, he has no more choice about falling than a stone has. As an organism, he is subjected to various biological laws which he cannot\n",
      "{'source': 'data/books/Mere-Christianity-CSLewis-FullBook.md', 'start_index': 2833}\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "attempt to write a readonly database",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcreate_database\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_data_store, load_documents\n\u001b[0;32m----> 3\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_data_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/src/create_database.py:26\u001b[0m, in \u001b[0;36mgenerate_data_store\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m documents \u001b[38;5;241m=\u001b[39m load_documents()\n\u001b[1;32m     25\u001b[0m chunks \u001b[38;5;241m=\u001b[39m split_text(documents)\n\u001b[0;32m---> 26\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43msave_to_chroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vector_store\n",
      "File \u001b[0;32m~/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/src/create_database.py:59\u001b[0m, in \u001b[0;36msave_to_chroma\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m     56\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(CHROMA_PATH)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Create a new DB from the documents.\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHROMA_PATH\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# db.persist is no longer needed because documents are automatically persisted.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# db.persist()\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m chunks to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHROMA_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/.venv/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:790\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    789\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 790\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/.venv/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:748\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[1;32m    743\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m    744\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    745\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[1;32m    746\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    747\u001b[0m     ):\n\u001b[0;32m--> 748\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    754\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[0;32m~/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/.venv/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:298\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m ids_with_metadata \u001b[38;5;241m=\u001b[39m [ids[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m non_empty_ids]\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/.venv/lib/python3.9/site-packages/chromadb/api/models/Collection.py:487\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mimages)\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/.venv/lib/python3.9/site-packages/chromadb/telemetry/opentelemetry/__init__.py:143\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/.venv/lib/python3.9/site-packages/chromadb/api/segment.py:474\u001b[0m, in \u001b[0;36mSegmentAPI._upsert\u001b[0;34m(self, collection_id, ids, embeddings, metadatas, documents, uris)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_embedding_record(coll, r)\n\u001b[1;32m    473\u001b[0m     records_to_submit\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[0;32m--> 474\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_producer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords_to_submit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/.venv/lib/python3.9/site-packages/chromadb/telemetry/opentelemetry/__init__.py:143\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/code/10Academy-training/week7/Prompt-Tuning-Enterprise-RAG/.venv/lib/python3.9/site-packages/chromadb/db/mixins/embeddings_queue.py:180\u001b[0m, in \u001b[0;36mSqlEmbeddingsQueue.submit_embeddings\u001b[0;34m(self, collection_id, embeddings)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# The returning clause does not guarantee order, so we need to do reorder\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# the results. https://www.sqlite.org/lang_returning.html\u001b[39;00m\n\u001b[1;32m    179\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m RETURNING seq_id, id\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Pypika doesn't support RETURNING\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Reorder the results\u001b[39;00m\n\u001b[1;32m    182\u001b[0m seq_ids \u001b[38;5;241m=\u001b[39m [cast(SeqId, \u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    183\u001b[0m     results\n\u001b[1;32m    184\u001b[0m )  \u001b[38;5;66;03m# Lie to mypy: https://stackoverflow.com/questions/76694215/python-type-casting-when-preallocating-list\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: attempt to write a readonly database"
     ]
    }
   ],
   "source": [
    "from src.create_database import generate_data_store, load_documents\n",
    "\n",
    "vectorstore = generate_data_store()\n",
    "documents = load_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get documents from github blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.env_loader import load_api_key\n",
    "load_api_key()\n",
    "# os.environ[\"OPENAPI_API_KEY\"] = \"sk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INDEXING ####\n",
    "\n",
    "# Load blog\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "\n",
    "from src.env_loader import load_api_key\n",
    "load_api_key()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  temperature=0\n",
    ")\n",
    "\n",
    "llm_critic = ChatOpenAI(\n",
    "  model=\"gpt-4\",\n",
    "  temperature=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHROMA_PATH = \"../../chroma\"\n",
    "# DATA_PATH = \"../../data/books\"\n",
    "\n",
    "# vectorstore = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context,conditional\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "testsetgenerator = TestsetGenerator.from_langchain(\n",
    "  generator_llm=llm,\n",
    "  critic_llm=llm_critic,\n",
    "  embeddings=embeddings,\n",
    ")\n",
    "\n",
    "distributions={\n",
    "  simple: 0.5, \n",
    "  reasoning: 0.25, \n",
    "  multi_context: 0.25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 5\n",
    "testset = testsetgenerator.generate_with_langchain_docs(documents, test_size=test_size, distributions=distributions, is_async=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the test set to chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the Christian perspective on the exist...</td>\n",
       "      <td>[ really good, then you cannot talk like that....</td>\n",
       "      <td>The Christian perspective acknowledges that Go...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/books/Mere-Christianity-CSLe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the concept of the Three-Personal life...</td>\n",
       "      <td>[ God contains at least two Persons. Love is s...</td>\n",
       "      <td>The concept of the Three-Personal life in Chri...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/books/Mere-Christianity-CSLe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is C.S. Lewis' view on the ultimate goal ...</td>\n",
       "      <td>[) that everyone else ought to have the same i...</td>\n",
       "      <td>C.S. Lewis views the ultimate goal of human li...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/books/Mere-Christianity-CSLe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the Christian perspective on the exist...   \n",
       "1  What is the concept of the Three-Personal life...   \n",
       "2  What is C.S. Lewis' view on the ultimate goal ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [ really good, then you cannot talk like that....   \n",
       "1  [ God contains at least two Persons. Love is s...   \n",
       "2  [) that everyone else ought to have the same i...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The Christian perspective acknowledges that Go...         simple   \n",
       "1  The concept of the Three-Personal life in Chri...         simple   \n",
       "2  C.S. Lewis views the ultimate goal of human li...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'data/books/Mere-Christianity-CSLe...          True  \n",
       "1  [{'source': 'data/books/Mere-Christianity-CSLe...          True  \n",
       "2  [{'source': 'data/books/Mere-Christianity-CSLe...          True  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "testset.to_pandas().to_csv(\"./output.csv\", index=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# loader = TextLoader(\"./nyc_wikipedia/nyc_text.txt\")\n",
    "# index = VectorstoreIndexCreator().from_loaders([loader])\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The two odd things about human beings mentioned in the text are:\\n\\n1. Human beings have a sense that they ought to behave in a certain way (fair play, decency, morality, or the Law of Nature), but they often do not follow this behavior.\\n2. The human race is haunted by the idea of a sort of behavior they ought to practice, but they do not actually do so.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing it out\n",
    "\n",
    "question = \"What are the two odd things about human beings?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload and verify the test set with Langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a new dataset 'Mere Christianity'. Dataset is accessible at https://smith.langchain.com/o/6691a6dd-a70e-56c0-8f45-a1f64338d797/datasets/3a1417ed-d49d-444b-a3cd-cdf43195971c\n"
     ]
    }
   ],
   "source": [
    "from ragas.integrations.langsmith import upload_dataset\n",
    "\n",
    "dataset_name = \"Mere Christianity\"\n",
    "dataset_desc = \"Synthetic testset data for Mere Christianity.\"\n",
    "\n",
    "dataset = upload_dataset(testset, dataset_name, dataset_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"What is the Christian perspective on the existence of a good God in relation to the world's injustices and complexities?\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get one example question for the dataset for testing\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "examples = list(client.list_examples(dataset_name=\"Mere Christianity\"))\n",
    "\n",
    "q = examples[0].inputs\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Retrieve and generate using the relevant snippets from the docs\n",
    "vectorstore_retriever = vectorstore.as_retriever()\n",
    "# load a RAG prompt from Langchain HUB\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# our llm of choice\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "def ragas_output_parser(docs):\n",
    "    return [doc.page_content for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "generator = prompt | llm | StrOutputParser()\n",
    "\n",
    "retriever = RunnableParallel(\n",
    "    {\n",
    "        \"context\": vectorstore_retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    ")\n",
    "\n",
    "filter_langsmith_dataset = RunnableLambda(\n",
    "    lambda x: x[\"question\"] if isinstance(x, dict) else x\n",
    ")\n",
    "\n",
    "rag_chain = RunnableParallel(\n",
    "    {\n",
    "        \"question\": filter_langsmith_dataset,\n",
    "        \"answer\": filter_langsmith_dataset | retriever | generator,\n",
    "        \"contexts\": filter_langsmith_dataset\n",
    "        | vectorstore_retriever\n",
    "        | ragas_output_parser,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Christian perspective is that the world is good but has gone wrong due to sin and the influence of an evil power. Christians believe that God allows free will, which can lead to injustices and complexities in the world. The existence of evil and suffering is seen as a result of the fallen nature of humanity and the presence of sin.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check with the example question to see if everything is working\n",
    "get_answer = RunnableLambda(lambda x: x[\"answer\"])\n",
    "resp = (rag_chain | get_answer).invoke(q)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "llm_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "just_llm = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | llm_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | RunnableParallel(\n",
    "        {\n",
    "            \"answer\": RunnablePassthrough(),\n",
    "            \"contexts\": RunnableLambda(lambda _: [\"\"]),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Christian perspective is that God is good and just, but the world's injustices and complexities are a result of human sin and free will. Christians believe that God works through these challenges to bring about good and ultimately redeem the world. Thanks for asking!\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = (just_llm | get_answer).invoke(q)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EvaluatorChain from Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.integrations.langchain import EvaluatorChain\n",
    "\n",
    "# the metric we will be using\n",
    "from ragas.metrics import answer_correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Langsmith dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.integrations.langsmith import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'rag_chain_1' at:\n",
      "https://smith.langchain.com/o/6691a6dd-a70e-56c0-8f45-a1f64338d797/datasets/3a1417ed-d49d-444b-a3cd-cdf43195971c/compare?selectedSessions=db22ad58-dc6a-45f6-89c1-bec250826d4b\n",
      "\n",
      "View all tests for Dataset Mere Christianity at:\n",
      "https://smith.langchain.com/o/6691a6dd-a70e-56c0-8f45-a1f64338d797/datasets/3a1417ed-d49d-444b-a3cd-cdf43195971c\n",
      "[------------------------------------------------->] 3/3"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.answer_correctness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b03c8f06-bec1-4822-9127-12ec086c1b7e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.740585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.283853</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.289583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.736581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.057360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.739464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.120712</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.742348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.184064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.742587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.397099</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.742826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.610135</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.answer_correctness error  execution_time  \\\n",
       "count                      3.000000     0        3.000000   \n",
       "unique                          NaN     0             NaN   \n",
       "top                             NaN   NaN             NaN   \n",
       "freq                            NaN   NaN             NaN   \n",
       "mean                       0.740585   NaN        3.283853   \n",
       "std                        0.003476   NaN        0.289583   \n",
       "min                        0.736581   NaN        3.057360   \n",
       "25%                        0.739464   NaN        3.120712   \n",
       "50%                        0.742348   NaN        3.184064   \n",
       "75%                        0.742587   NaN        3.397099   \n",
       "max                        0.742826   NaN        3.610135   \n",
       "\n",
       "                                      run_id  \n",
       "count                                      3  \n",
       "unique                                     3  \n",
       "top     b03c8f06-bec1-4822-9127-12ec086c1b7e  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate Rag chain first\n",
    "dataset_name = \"Mere Christianity\"\n",
    "# evaluate just llms\n",
    "run = evaluate(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=rag_chain,\n",
    "    experiment_name=\"rag_chain_1\",\n",
    "    metrics=[answer_correctness],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's evaluate the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'just_llm_1' at:\n",
      "https://smith.langchain.com/o/6691a6dd-a70e-56c0-8f45-a1f64338d797/datasets/3a1417ed-d49d-444b-a3cd-cdf43195971c/compare?selectedSessions=732cb598-7386-4ddb-a64a-b667da57618a\n",
      "\n",
      "View all tests for Dataset Mere Christianity at:\n",
      "https://smith.langchain.com/o/6691a6dd-a70e-56c0-8f45-a1f64338d797/datasets/3a1417ed-d49d-444b-a3cd-cdf43195971c\n",
      "[------------------------------------------------->] 3/3"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.answer_correctness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4ab30b13-4f68-4dd6-bc5f-3245d5d1a3ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.489599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.080425</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.156267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.323743</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.333902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.878837</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.411183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.893709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.488464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.908582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.567447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.181220</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.646430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.453857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.answer_correctness error  execution_time  \\\n",
       "count                      3.000000     0        3.000000   \n",
       "unique                          NaN     0             NaN   \n",
       "top                             NaN   NaN             NaN   \n",
       "freq                            NaN   NaN             NaN   \n",
       "mean                       0.489599   NaN        2.080425   \n",
       "std                        0.156267   NaN        0.323743   \n",
       "min                        0.333902   NaN        1.878837   \n",
       "25%                        0.411183   NaN        1.893709   \n",
       "50%                        0.488464   NaN        1.908582   \n",
       "75%                        0.567447   NaN        2.181220   \n",
       "max                        0.646430   NaN        2.453857   \n",
       "\n",
       "                                      run_id  \n",
       "count                                      3  \n",
       "unique                                     3  \n",
       "top     4ab30b13-4f68-4dd6-bc5f-3245d5d1a3ff  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate rag_chain\n",
    "run = evaluate(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=just_llm,\n",
    "    experiment_name=\"just_llm_1\",\n",
    "    metrics=[answer_correctness],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d11814ba-e5f9-4487-b2c8-505670c2ec83',\n",
       " 'cf6bf697-e1ce-4a14-8159-50c77434a03f',\n",
       " 'd76c8ad7-4639-4918-a33c-634f4fb79373']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# questions = test_df[\"question\"].tolist()\n",
    "# ground_truths = test_df[\"ground_truth\"].tolist()\n",
    "# metadata = test_df[\"metadata\"].tolist()\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "# Change the df columns to lists\n",
    "texts = test_df['question'].tolist()\n",
    "metadatas = test_df.apply(lambda row: {'ground_truth': row['ground_truth'], **functools.reduce(operator.or_, row['metadata'], {})}, axis=1).tolist()\n",
    "\n",
    "vectorstore = Chroma(persist_directory=\"../../chroma\", embedding_function=embeddings)\n",
    "\n",
    "vectorstore.add_texts(texts, metadatas=metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Chroma' object has no attribute 'get_all_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve all IDs\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m all_ids \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_ids\u001b[49m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Retrieve the text and metadata for each ID\u001b[39;00m\n\u001b[1;32m      5\u001b[0m all_texts \u001b[38;5;241m=\u001b[39m [vectorstore\u001b[38;5;241m.\u001b[39mget_text_and_metadata(\u001b[38;5;28mid\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_ids]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Chroma' object has no attribute 'get_all_ids'"
     ]
    }
   ],
   "source": [
    "# # Retrieve all IDs\n",
    "# all_ids = vectorstore.get_all_ids()\n",
    "\n",
    "# # Retrieve the text and metadata for each ID\n",
    "# all_texts = [vectorstore.get_text_and_metadata(id) for id in all_ids]\n",
    "\n",
    "# # all_texts is a list of tuples. Each tuple contains a text and its associated metadata.\n",
    "# for text, metadata in all_texts:\n",
    "#     print(f'Text: {text}')\n",
    "#     print(f'Metadata: {metadata}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import context_precision, faithfulness, answer_relevancy, context_recall\n",
    "\n",
    "data = {\n",
    "    'question': [\"What are the two odd things about the Human Race?\"],\n",
    "    'answer': [response_text],\n",
    "    'contexts': [[doc.page_content for doc, _score in results]]\n",
    "}\n",
    "\n",
    "result = evaluate(\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pandas()\n",
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
