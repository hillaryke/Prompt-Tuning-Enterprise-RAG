{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rag final Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.test_cases import TestCase, generate_test_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate test cases examples for testing the implementation of the Rag algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  {\n",
    "    \"scenario\": \"The user is curious about the concept of few shot learning.\",\n",
    "    \"expected_output\": \"An explanation of few shot learning principles including its definition, importance, and examples in machine learning applications is provided.\"\n",
    "  },\n",
    "  {\n",
    "    \"scenario\": \"A student is researching the different types of machine learning approaches.\",\n",
    "    \"expected_output\": \"A concise but informative overview of few shot learning compared to other machine learning methods like supervised and unsupervised learning is delivered.\"\n",
    "  },\n",
    "  {\n",
    "    \"scenario\": \"An AI enthusiast is preparing a presentation on advanced machine learning techniques.\",\n",
    "    \"expected_output\": \"Detailed insights into the advantages, challenges, implementation scenarios, and recent developments related to few shot learning are presented.\"\n",
    "  }\n",
    "]\n",
    "\n",
    "def generate_test_cases_from_examples(examples):\n",
    "    test_cases = []\n",
    "    for example in examples:\n",
    "      test_case = TestCase(scenario=example[\"scenario\"], expected_output=example[\"expected_output\"])\n",
    "      test_cases.append(test_case)\n",
    "    return test_cases\n",
    "\n",
    "test_cases = generate_test_cases_from_examples(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_description = \"What is few shot learning?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the test cases using GPT model\n",
    "# test_cases = generate_test_cases(task_description, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from app.prompts_generation.generate_prompt_candidates import PromptGenerator\n",
    "\n",
    "# prompt_generator = PromptGenerator()\n",
    "# candidates = prompt_generator.generate_prompt_candidates(test_cases, task_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use these prompt candidates as examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_candidates = [\n",
    "  'Discuss distinctive features of Few shot learning.',\n",
    "  'Explain the essence of Few shot learning techniques.',\n",
    "  'How does Few shot learning revolutionize machine learning approaches?'\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get retreiver from Chroma vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.rag.loaders.load_web_docs import load_docs_from_web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 153 chunks.\n",
      "Saved 153 chunks to Chroma.\n"
     ]
    }
   ],
   "source": [
    "retriever = load_docs_from_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate answer for a given prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7e354fec1580>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from app.generator.generate_answers import generate_answer\n",
    "\n",
    "# answer_a = generate_answer(prompt_candidates[0], test_cases[2], retriever)\n",
    "# answer_b = generate_answer(prompt_candidates[1], test_cases[2], retriever)\n",
    "# answer_a\n",
    "# answer_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the scores comparing prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.evaluation import get_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample Usage to Test get_score()\n",
    "test_case = test_cases[2]\n",
    "prompt_a = prompt_candidates[0]\n",
    "prompt_b = prompt_candidates[1]\n",
    "\n",
    "# #Get scores\n",
    "# score = get_score(task_description, test_case, prompt_a, prompt_b, retriever)\n",
    "\n",
    "# print(\"Scores:\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using monte carlo matchmaking to generate the best prompt for a given answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking prompts with Elo Ranking system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.evaluation.prompt_ranking_elo import rank_prompts_with_elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['Chroma', 'OpenAIEmbeddings'] vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7e354fec1580> search_kwargs={'k': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n",
      "USING LLM to compare prompts\n"
     ]
    }
   ],
   "source": [
    "ranked_prompts = rank_prompts_with_elo(task_description, prompt_candidates, test_cases, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Discuss distinctive features of Few shot learning.',\n",
       " 'How does Few shot learning revolutionize machine learning approaches?',\n",
       " 'Explain the essence of Few shot learning techniques.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
