{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question_schema = ResponseSchema(\n",
    "    name=\"questions\",\n",
    "    description=\"list of questions about the context with the example: ['What is rag'].\",\n",
    "    type=\"array(str)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question_response_schemas = [\n",
    "    question_schema,\n",
    "]\n",
    "\n",
    "question_output_parser = StructuredOutputParser.from_response_schemas(question_response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='questions', description=\"list of questions about the context with the example: ['What is rag'].\", type='array(str)')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "format_instructions = question_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"questions\": array(str)  // list of questions about the context with the example: [\\'What is rag\\'].\\n}\\n```'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generation_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bare_prompt_template = \"{content}\"\n",
    "bare_template = ChatPromptTemplate.from_template(template=bare_prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa_template = \"\"\"\\\n",
    "You are a University Professor creating a test for advanced students. For each context, create 5 question that is specific to the context. Avoid creating generic or general questions.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "questions:\n",
    "\n",
    "Format the output as the following:\n",
    "questions: [\n",
    "    \"Question 1\",\n",
    "    \"Question 2\"\n",
    "]\n",
    "\n",
    "context: {context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(template=qa_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='You are a University Professor creating a test for advanced students. For each context, create 5 question that is specific to the context. Avoid creating generic or general questions.\\n\\nFormat the output as JSON with the following keys:\\nquestions:\\n\\nFormat the output as the following:\\nquestions: [\\n    \"Question 1\",\\n    \"Question 2\"\\n]\\n\\ncontext: {context}\\n'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt_template.format_messages(\n",
    "    context=get_context_for_user_objective(user_prompt),\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "\n",
    "question_generation_chain = bare_template | question_generation_llm\n",
    "\n",
    "response = question_generation_chain.invoke({\"content\" : messages})\n",
    "questions_dict = question_output_parser.parse(response.content)\n",
    "print(questions_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
